#!/usr/bin/env python3
"""
WeChat Summarizer - Specialized summarizer for WeChat sharing

Creates concise, readable summaries optimized for WeChat group sharing.
Focuses on buy/sell recommendations, key data points, and investment logic.
"""

import re
from src.llm_summarizer import LLMSummarizer

class WeChatSummarizer:
    def __init__(self):
        """Initialize WeChat summarizer with LLM backend."""
        self.llm_summarizer = LLMSummarizer()
        
    def generate_wechat_summary(self, pdf_text, filename=""):
        """
        Generate WeChat-friendly summary from PDF text.
        
        Args:
            pdf_text (str): Raw text extracted from PDF
            filename (str): Original filename for source attribution
            
        Returns:
            str: Formatted WeChat summary (â‰¤300 characters)
        """
        try:
            # Create specialized prompt for WeChat format
            wechat_prompt = self._create_wechat_prompt(pdf_text, filename)
            
            # Get LLM summary using existing infrastructure
            if self.llm_summarizer.deepseek_available:
                try:
                    print("ðŸ“± æ­£åœ¨ä½¿ç”¨DeepSeekç”Ÿæˆå¾®ä¿¡åˆ†äº«æ ¼å¼...")
                    summary = self._summarize_with_deepseek_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ DeepSeekå¤±è´¥: {e}")
            
            if self.llm_summarizer.gemini_available:
                try:
                    print("ðŸ“± æ­£åœ¨ç”Ÿæˆå¾®ä¿¡åˆ†äº«æ ¼å¼...")
                    summary = self._summarize_with_gemini_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ Geminiå¤±è´¥: {e}")
            
            if self.llm_summarizer.qwen_available:
                try:
                    print("ðŸ“± ä½¿ç”¨Qwenç”Ÿæˆå¾®ä¿¡æ ¼å¼...")
                    summary = self._summarize_with_qwen_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ Qwenå¤±è´¥: {e}")
            
            # Fallback to basic extraction
            return self._fallback_summary(pdf_text, filename)
            
        except Exception as e:
            return f"âŒ åˆ†æžå¤±è´¥: {filename}\né”™è¯¯: {str(e)}"
    
    def _create_wechat_prompt(self, pdf_text, filename):
        """Create specialized prompt for WeChat summary."""
        # Truncate text if too long
        max_length = 15000
        if len(pdf_text) > max_length:
            pdf_text = pdf_text[:max_length] + "\n\n[å†…å®¹å·²æˆªæ–­...]"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œéœ€è¦ä¸ºå¾®ä¿¡ç¾¤åˆ†äº«åˆ›å»ºå†…å®¹è¯¦å®žã€è®ºæ®å……åˆ†çš„ç ”æŠ¥æ€»ç»“ã€‚

**å¤„ç†æµç¨‹ï¼š**
1.  **è¯†åˆ«æ¥æºä¸Žå¯¹è±¡**ï¼šé¦–å…ˆå‡†ç¡®è¯†åˆ«ç ”æŠ¥çš„**å‘å¸ƒæœºæž„**ï¼ˆå¦‚é«˜ç››ã€æ‘©æ ¹å¤§é€šï¼‰åŠå…¶ä¸»è¦åˆ†æžçš„**å…¬å¸æˆ–è¡Œä¸š**ã€‚
2.  **æç‚¼æ ¸å¿ƒè§‚ç‚¹ä¸Žç»“è®º**ï¼šå®¢è§‚æç‚¼æŠ¥å‘Šçš„æ ¸å¿ƒåˆ¤æ–­ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºŽï¼šè¡Œä¸šè¶‹åŠ¿é¢„æµ‹ã€å…¬å¸å‰æ™¯å±•æœ›ã€æŠ•èµ„è¯„çº§ï¼ˆå¢žæŒ/ä¹°å…¥/ä¸­æ€§ç­‰ï¼‰åŠç›®æ ‡ä»·ã€‚
3.  **è¯¦å®žæ€»ç»“æ”¯æ’‘è®ºæ®**ï¼šè¿™æ˜¯å…³é”®ã€‚å¿…é¡»æ·±å…¥æå–æ”¯æŒå…¶æ ¸å¿ƒç»“è®ºçš„**2-3ä¸ªä¸»è¦é€»è¾‘å’Œå…³é”®æ•°æ®**ä½œä¸ºæ”¯æ’‘è®ºç‚¹ï¼Œè¦æ±‚å…·ä½“ã€è¯¦å®žã€‚
4.  **èšç„¦å…³é”®æ•°æ®**ï¼šçªå‡ºå‘ˆçŽ°æœ€é‡è¦çš„å…·ä½“æ•°æ®ï¼Œå¦‚å¢žé•¿çŽ‡ã€å¸‚åœºä»½é¢ã€è§„æ¨¡é¢„æµ‹ã€ä¼°å€¼å€æ•°ã€è®¢å•æƒ…å†µç­‰ã€‚
5.  **ä¸¥æ ¼è§„é¿å†…å®¹**ï¼šåˆ é™¤æ‰€æœ‰é£Žé™©æç¤ºã€å…è´£å£°æ˜Žã€ä¸»è§‚è‡†æ–­åŠå†—ä½™èƒŒæ™¯ä¿¡æ¯ã€‚

**è¾“å‡ºè¦æ±‚ï¼š**
-   **è¯­è¨€**ï¼šçº¯ä¸­æ–‡ï¼Œè¡Œæ–‡ä¸“ä¸šä¸”å¹³å®žï¼Œé€‚åˆé‡‘èžä»Žä¸šè€…é˜…è¯»ã€‚
-   **å­—æ•°**ï¼š**200è‡³400å­—ä¹‹é—´**ï¼Œç¡®ä¿å†…å®¹å……å®žä¸”ä¸è¶…é™ã€‚
-   **å†…å®¹**ï¼šå¿…é¡»ä¸¥æ ¼åŸºäºŽç ”æŠ¥åŽŸæ–‡ï¼Œå®¢è§‚å‘ˆçŽ°å…¶è§‚ç‚¹ä¸Žè®ºæ®ã€‚
-   **æ ¼å¼**ï¼šè¾“å‡ºä¸ºä¸€æ®µè¯ï¼Œæ— éœ€åˆ†ç‚¹

**è¾“å‡ºæ ¼å¼ï¼š**
[æœºæž„åç§°]å‘å¸ƒå…³äºŽ[å…¬å¸åç§°/è¡Œä¸šåç§°]çš„æœ€æ–°ç ”ç©¶ã€‚[å…¶ä¸»è¦è§‚ç‚¹/è®¤ä¸º]ï¼š[ç”¨1-2å¥è¯æ¦‚æ‹¬æ ¸å¿ƒåˆ¤æ–­æˆ–è¶‹åŠ¿é¢„æµ‹]ã€‚æ ¸å¿ƒæ”¯æ’‘è®ºæ®åŒ…æ‹¬ï¼š[è¯¦ç»†è¯´æ˜Ž2-3ä¸ªæ”¯æ’‘è®ºç‚¹ï¼Œæ¯ä¸ªè®ºç‚¹åŒ…å«å…·ä½“æ•°æ®æˆ–äº‹å®ž]ã€‚[å¦‚ç ”æŠ¥æä¾›]åŸºäºŽä¸Šè¿°åˆ†æžï¼Œ[æœºæž„åç§°][ç»´æŒ/ç»™äºˆ][è‚¡ç¥¨ä»£ç ]"[è¯„çº§]"è¯„çº§ï¼Œ[å¹¶æä¾›å…·ä½“çš„é¢„æµ‹è°ƒæ•´è¯´æ˜Žï¼Œå¦‚"å°†2025-2030å¹´èµ„æœ¬æ”¯å‡ºé¢„æµ‹ä¸Šè°ƒè‡³XXèŒƒå›´"æˆ–"é¢„è®¡2025-2027å¹´è¥æ”¶å¤åˆå¢žé€Ÿè¾¾X%"]ã€‚[å¦‚é€‚ç”¨]åŸºäºŽ[ä¼°å€¼æ–¹æ³•]ï¼Œ[ç»´æŒ/è®¾å®š]ç›®æ ‡ä»·[ç›®æ ‡ä»·æ ¼]ã€‚

**å‚è€ƒæ¡ˆä¾‹ï¼ˆä¸ªè‚¡ï¼‰ï¼š**
æ‘©æ ¹å¤§é€šå‘å¸ƒå…³äºŽä¸­å¾®å…¬å¸çš„æœ€æ–°ç ”ç©¶ã€‚å…¶è®¤ä¸ºå…¬å¸é•¿æœŸå‰æ™¯ä¾ç„¶ä¹è§‚ï¼Œå°†å—ç›ŠäºŽè®¾å¤‡å›½äº§åŒ–è¶‹åŠ¿ã€‚æ ¸å¿ƒæ”¯æ’‘è®ºæ®åŒ…æ‹¬ï¼šQ2è¥æ”¶ä¸Žåˆ©æ¶¦ä¿æŒå¼ºåŠ²å¢žé•¿ï¼ŒåŒæ¯”åˆ†åˆ«å¢žé•¿51%å’Œ47%ï¼›äº§å“å¤šå…ƒåŒ–è¿›å±•æ˜¾è‘—ï¼ŒICPè®¢å•å·²è¶…è¿‡CCPï¼Œè–„è†œä¸šåŠ¡å¢žé€Ÿè¿…çŒ›ï¼›åˆåŒè´Ÿå€ºä¸Žåº“å­˜æŒç»­ä¸Šå‡é¢„ç¤ºéœ€æ±‚ç¨³å¥ã€‚åŸºäºŽä¸Šè¿°åˆ†æžï¼Œæ‘©æ ¹å¤§é€šç»´æŒä¸­å¾®å…¬å¸"å¢žæŒ"è¯„çº§ï¼Œé¢„è®¡2025-2027å¹´å…¬å¸è¥æ”¶/ç›ˆåˆ©å¤åˆå¢žé€Ÿè¾¾49%/65%ã€‚åŸºäºŽ20å€2026å¹´é¢„æœŸå¸‚ç›ˆçŽ‡ï¼Œç»´æŒç›®æ ‡ä»·230å…ƒã€‚

**å‚è€ƒæ¡ˆä¾‹ï¼ˆè¡Œä¸šï¼‰ï¼š**
é«˜ç››å‘å¸ƒå…³äºŽä¸­å›½åŠå¯¼ä½“è¡Œä¸šçš„æœ€æ–°ç ”ç©¶ã€‚æŠ¥å‘ŠæŒ‡å‡ºä¸­å›½åŠå¯¼ä½“è¡Œä¸šæ­£è¿Žæ¥æ–°ä¸€è½®èµ„æœ¬æ”¯å‡ºæ‰©å¼ ä¸ŽæŠ€æœ¯å‡çº§ã€‚æ ¸å¿ƒæ”¯æ’‘è®ºæ®åŒ…æ‹¬ï¼šå°†2025-2030å¹´èµ„æœ¬æ”¯å‡ºé¢„æµ‹ä¸Šè°ƒè‡³430-460äº¿ç¾Žå…ƒï¼›é¢„è®¡æŠ•èµ„é‡ç‚¹å°†æ›´å¤šè½¬å‘å­˜å‚¨å™¨å’Œå…ˆè¿›åˆ¶ç¨‹èŠ‚ç‚¹ï¼›æœ¬åœŸSPEä¾›åº”å•†å¯èƒ½å—ç›Šï¼Œé¢„è®¡å…¶å¸‚åœºä»½é¢å°†ä»Ž2025å¹´çš„26%æå‡è‡³2030å¹´çš„36%ï¼›æå‡ºåˆ°2035å¹´ä¸­å›½éœ€æ–°å¢žè¶…2261å°å…‰åˆ»æœºä»¥æ»¡è¶³èŠ¯ç‰‡å…¨éœ€æ±‚ã€‚

**å‚è€ƒæ¡ˆä¾‹ï¼ˆæ— å…·ä½“ä¼°å€¼ï¼‰ï¼š**
ä¸­ä¿¡è¯åˆ¸å‘å¸ƒå…³äºŽæ–°èƒ½æºè¡Œä¸šçš„æœ€æ–°ç ”ç©¶ã€‚æŠ¥å‘Šè®¤ä¸ºè¡Œä¸šå°†è¿›å…¥æ–°ä¸€è½®æ™¯æ°”å‘¨æœŸã€‚æ ¸å¿ƒæ”¯æ’‘è®ºæ®åŒ…æ‹¬ï¼šé¢„è®¡2024-2026å¹´å…¨çƒå…‰ä¼è£…æœºé‡å¤åˆå¢žé•¿çŽ‡è¾¾25%ï¼›é”‚ç”µæ± æˆæœ¬æŒç»­ä¸‹é™ï¼Œå‚¨èƒ½ç»æµŽæ€§æ˜¾è‘—æå‡ï¼›æ”¿ç­–æ”¯æŒåŠ›åº¦åŠ å¤§ï¼Œå¤šå›½æå‡ºç¢³ä¸­å’Œç›®æ ‡ã€‚åŸºäºŽä¸Šè¿°åˆ†æžï¼Œä¸­ä¿¡è¯åˆ¸çœ‹å¥½å…‰ä¼äº§ä¸šé“¾å’Œå‚¨èƒ½ç³»ç»Ÿé›†æˆå•†çš„å‘å±•å‰æ™¯ã€‚

è¯·æ ¹æ®ä¸Šè¿°è§„åˆ™ï¼Œå¯¹ä»¥ä¸‹æ–‡æ¡£è¿›è¡Œåˆ†æžå’Œæ€»ç»“ï¼š
æ–‡æ¡£: {filename}
å†…å®¹: {pdf_text}
"""
        return prompt
    
    def _summarize_with_deepseek_wechat(self, prompt):
        """Use DeepSeek for WeChat summary."""
        response = self.llm_summarizer.deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œæ“…é•¿åˆ›å»ºç®€æ´çš„å¾®ä¿¡åˆ†äº«å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        return response.choices[0].message.content.strip()
    
    def _summarize_with_gemini_wechat(self, prompt):
        """Use Gemini for WeChat summary."""
        response = self.llm_summarizer.model.generate_content(prompt)
        return response.text.strip()
    
    def _summarize_with_qwen_wechat(self, prompt):
        """Use Qwen for WeChat summary."""
        response = self.llm_summarizer.qwen_client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œæ“…é•¿åˆ›å»ºç®€æ´çš„å¾®ä¿¡åˆ†äº«å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        return response.choices[0].message.content.strip()
    
    def _format_wechat_output(self, summary, filename):
        """Format and validate WeChat output."""
        # Clean up the summary
        summary = summary.strip()
        
        # Remove any markdown formatting
        summary = re.sub(r'\*\*([^*]+)\*\*', r'\1', summary)
        summary = re.sub(r'\*([^*]+)\*', r'\1', summary)
        
        # Ensure it's not too long (400 characters max)
        if len(summary) > 400:
            # Try to truncate at sentence boundary
            sentences = summary.split('ã€‚')
            truncated = ""
            for sentence in sentences:
                if len(truncated + sentence + "ã€‚") <= 395:
                    truncated += sentence + "ã€‚"
                else:
                    break
            if truncated:
                summary = truncated
            else:
                summary = summary[:395] + "..."
        
        return summary
    
    def _fallback_summary(self, pdf_text, filename):
        """Create basic summary when LLMs are unavailable."""
        # Extract key information using simple text processing
        lines = pdf_text.split('\n')
        
        # Look for common patterns
        company_name = self._extract_company_name(lines)
        rating = self._extract_rating(lines)
        target_price = self._extract_target_price(lines)
        source = self._extract_source(filename)
        
        summary = f"{source}è§‚ç‚¹: {company_name}\n"
        if rating:
            summary += f"{rating}è¯„çº§"
        if target_price:
            summary += f"ï¼Œç›®æ ‡ä»·{target_price}"
        
        summary += f"\nðŸ“„ æ¥æº: {filename}"
        
        return summary[:400]
    
    def _extract_company_name(self, lines):
        """Extract company name from text."""
        for line in lines[:10]:  # Check first 10 lines
            if any(keyword in line for keyword in ['è‚¡ä»½', 'å…¬å¸', 'ç§‘æŠ€', 'é›†å›¢']):
                # Simple extraction - could be improved
                words = line.split()
                for word in words:
                    if any(keyword in word for keyword in ['è‚¡ä»½', 'å…¬å¸', 'ç§‘æŠ€', 'é›†å›¢']):
                        return word[:10]  # Limit length
        return "ç›®æ ‡å…¬å¸"
    
    def _extract_rating(self, lines):
        """Extract investment rating."""
        rating_keywords = {
            'buy': 'ä¹°å…¥', 'overweight': 'å¢žæŒ', 'hold': 'æŒæœ‰', 
            'sell': 'å–å‡º', 'underweight': 'å‡æŒ',
            'ä¹°å…¥': 'ä¹°å…¥', 'å¢žæŒ': 'å¢žæŒ', 'æŒæœ‰': 'æŒæœ‰'
        }
        
        text = ' '.join(lines[:20]).lower()
        for eng, chn in rating_keywords.items():
            if eng in text:
                return chn
        return ""
    
    def _extract_target_price(self, lines):
        """Extract target price."""
        import re
        text = ' '.join(lines[:20])
        
        # Look for price patterns
        price_patterns = [
            r'ç›®æ ‡ä»·[ï¼š:]?\s*([Â¥$]?\d+\.?\d*)',
            r'target price[ï¼š:]?\s*([Â¥$]?\d+\.?\d*)',
            r'([Â¥$]?\d+\.?\d*)\s*å…ƒ',
            r'([Â¥$]?\d+\.?\d*)\s*æ¸¯å…ƒ'
        ]
        
        for pattern in price_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1)
        return ""
    
    def _extract_source(self, filename):
        """Extract source institution from filename."""
        sources = {
            'jpmorgan': 'æ‘©æ ¹å¤§é€š', 'jp': 'æ‘©æ ¹å¤§é€š', 'jpm': 'æ‘©æ ¹å¤§é€š',
            'goldman': 'é«˜ç››', 'gs': 'é«˜ç››',
            'morgan': 'æ‘©æ ¹å£«ä¸¹åˆ©', 'ms': 'æ‘©æ ¹å£«ä¸¹åˆ©',
            'citi': 'èŠ±æ——', 'citigroup': 'èŠ±æ——',
            'ubs': 'ç‘žé“¶', 'credit': 'ç‘žä¿¡',
            'bofa': 'ç¾Žé“¶', 'bank of america': 'ç¾Žé“¶'
        }
        
        filename_lower = filename.lower()
        for key, value in sources.items():
            if key in filename_lower:
                return value
        
        return "ç ”ç©¶æœºæž„"
    
    def combine_summaries(self, summaries):
        """Combine multiple summaries into one comprehensive summary."""
        if not summaries:
            return "æœªæ‰¾åˆ°æœ‰æ•ˆåˆ†æžç»“æžœ"
        
        if len(summaries) == 1:
            return summaries[0]
        
        # Extract common elements
        sources = set()
        companies = set()
        ratings = []
        
        for summary in summaries:
            # Extract source
            if 'è§‚ç‚¹:' in summary:
                source = summary.split('è§‚ç‚¹:')[0].strip()
                sources.add(source)
            
            # Extract ratings
            if 'ä¹°å…¥' in summary:
                ratings.append('ä¹°å…¥')
            elif 'å¢žæŒ' in summary:
                ratings.append('å¢žæŒ')
            elif 'æŒæœ‰' in summary:
                ratings.append('æŒæœ‰')
        
        # Create combined summary
        if sources:
            source_text = 'ã€'.join(list(sources)[:2])  # Max 2 sources
        else:
            source_text = "å¤šå®¶æœºæž„"
        
        # Determine consensus rating
        if ratings:
            most_common_rating = max(set(ratings), key=ratings.count)
        else:
            most_common_rating = "å…³æ³¨"
        
        combined = f"{source_text}ç»¼åˆè§‚ç‚¹:\n"
        combined += f"ä¸€è‡´{most_common_rating}è¯„çº§\n"
        combined += f"åŸºäºŽ{len(summaries)}ä»½ç ”æŠ¥çš„ç»¼åˆåˆ†æž\n"
        combined += "è¯¦ç»†è§‚ç‚¹è¯·è§ä¸Šæ–¹å„æœºæž„åˆ†æž"
        
        return combined[:400]
