#!/usr/bin/env python3
"""
WeChat Summarizer - Specialized summarizer for WeChat sharing

Creates concise, readable summaries optimized for WeChat group sharing.
Focuses on buy/sell recommendations, key data points, and investment logic.
"""

import re
from src.llm_summarizer import LLMSummarizer

class WeChatSummarizer:
    def __init__(self):
        """Initialize WeChat summarizer with LLM backend."""
        self.llm_summarizer = LLMSummarizer()
        
    def generate_wechat_summary(self, pdf_text, filename=""):
        """
        Generate WeChat-friendly summary from PDF text.
        
        Args:
            pdf_text (str): Raw text extracted from PDF
            filename (str): Original filename for source attribution
            
        Returns:
            str: Formatted WeChat summary (â‰¤300 characters)
        """
        try:
            # Create specialized prompt for WeChat format
            wechat_prompt = self._create_wechat_prompt(pdf_text, filename)
            
            # Get LLM summary using existing infrastructure
            if self.llm_summarizer.gemini_available:
                try:
                    print("ðŸ“± æ­£åœ¨ç”Ÿæˆå¾®ä¿¡åˆ†äº«æ ¼å¼...")
                    summary = self._summarize_with_gemini_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ Geminiå¤±è´¥: {e}")
            
            if self.llm_summarizer.qwen_available:
                try:
                    print("ðŸ“± ä½¿ç”¨Qwenç”Ÿæˆå¾®ä¿¡æ ¼å¼...")
                    summary = self._summarize_with_qwen_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ Qwenå¤±è´¥: {e}")
            
            # Fallback to basic extraction
            return self._fallback_summary(pdf_text, filename)
            
        except Exception as e:
            return f"âŒ åˆ†æžå¤±è´¥: {filename}\né”™è¯¯: {str(e)}"
    
    def _create_wechat_prompt(self, pdf_text, filename):
        """Create specialized prompt for WeChat summary."""
        # Truncate text if too long
        max_length = 15000
        if len(pdf_text) > max_length:
            pdf_text = pdf_text[:max_length] + "\n\n[å†…å®¹å·²æˆªæ–­...]"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œéœ€è¦ä¸ºå¾®ä¿¡ç¾¤åˆ†äº«åˆ›å»ºç®€æ´çš„ç ”æŠ¥æ€»ç»“ã€‚

æ–‡æ¡£: {filename}
å†…å®¹: {pdf_text}

è¦æ±‚:
1. è¾“å‡ºçº¯ä¸­æ–‡ï¼Œä¸è¶…è¿‡300ä¸ªæ±‰å­—
2. è¯­è¨€å¹³å®žï¼Œé€‚åˆå¾®ä¿¡ç¾¤åˆ†äº«
3. é‡ç‚¹æå–ä¹°å…¥/å–å‡ºæŽ¨èé€»è¾‘
4. çªå‡ºæ ¸å¿ƒæ•°æ®ï¼ˆå¢žé•¿çŽ‡ã€å¸‚å€¼ã€ç›®æ ‡ä»·ï¼‰
5. æ˜Žç¡®ç ”æŠ¥æ¥æºæœºæž„ï¼ˆå¦‚æ‘©æ ¹å¤§é€šã€é«˜ç››ç­‰ï¼‰
6. åˆ é™¤é£Žé™©æç¤ºã€å…è´£å£°æ˜Ž
7. æ ¼å¼ç®€æ´ï¼Œä¾¿äºŽé˜…è¯»

è¾“å‡ºæ ¼å¼:
[æœºæž„åç§°]è§‚ç‚¹: [å…¬å¸åç§°] 
[ä¹°å…¥/å–å‡º/ä¸­æ€§]è¯„çº§ï¼Œç›®æ ‡ä»·[å…·ä½“ä»·æ ¼]
æ ¸å¿ƒé€»è¾‘: [1-2å¥è¯è¯´æ˜Žä¸»è¦æŽ¨èç†ç”±]
å…³é”®æ•°æ®: [é‡è¦è´¢åŠ¡æŒ‡æ ‡æˆ–å¢žé•¿é¢„æœŸ]
"""
        return prompt
    
    def _summarize_with_gemini_wechat(self, prompt):
        """Use Gemini for WeChat summary."""
        response = self.llm_summarizer.model.generate_content(prompt)
        return response.text.strip()
    
    def _summarize_with_qwen_wechat(self, prompt):
        """Use Qwen for WeChat summary."""
        response = self.llm_summarizer.qwen_client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œæ“…é•¿åˆ›å»ºç®€æ´çš„å¾®ä¿¡åˆ†äº«å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        return response.choices[0].message.content.strip()
    
    def _format_wechat_output(self, summary, filename):
        """Format and validate WeChat output."""
        # Clean up the summary
        summary = summary.strip()
        
        # Remove any markdown formatting
        summary = re.sub(r'\*\*([^*]+)\*\*', r'\1', summary)
        summary = re.sub(r'\*([^*]+)\*', r'\1', summary)
        
        # Ensure it's not too long (300 characters max)
        if len(summary) > 300:
            # Try to truncate at sentence boundary
            sentences = summary.split('ã€‚')
            truncated = ""
            for sentence in sentences:
                if len(truncated + sentence + "ã€‚") <= 295:
                    truncated += sentence + "ã€‚"
                else:
                    break
            if truncated:
                summary = truncated
            else:
                summary = summary[:295] + "..."
        
        return summary
    
    def _fallback_summary(self, pdf_text, filename):
        """Create basic summary when LLMs are unavailable."""
        # Extract key information using simple text processing
        lines = pdf_text.split('\n')
        
        # Look for common patterns
        company_name = self._extract_company_name(lines)
        rating = self._extract_rating(lines)
        target_price = self._extract_target_price(lines)
        source = self._extract_source(filename)
        
        summary = f"{source}è§‚ç‚¹: {company_name}\n"
        if rating:
            summary += f"{rating}è¯„çº§"
        if target_price:
            summary += f"ï¼Œç›®æ ‡ä»·{target_price}"
        
        summary += f"\nðŸ“„ æ¥æº: {filename}"
        
        return summary[:300]
    
    def _extract_company_name(self, lines):
        """Extract company name from text."""
        for line in lines[:10]:  # Check first 10 lines
            if any(keyword in line for keyword in ['è‚¡ä»½', 'å…¬å¸', 'ç§‘æŠ€', 'é›†å›¢']):
                # Simple extraction - could be improved
                words = line.split()
                for word in words:
                    if any(keyword in word for keyword in ['è‚¡ä»½', 'å…¬å¸', 'ç§‘æŠ€', 'é›†å›¢']):
                        return word[:10]  # Limit length
        return "ç›®æ ‡å…¬å¸"
    
    def _extract_rating(self, lines):
        """Extract investment rating."""
        rating_keywords = {
            'buy': 'ä¹°å…¥', 'overweight': 'å¢žæŒ', 'hold': 'æŒæœ‰', 
            'sell': 'å–å‡º', 'underweight': 'å‡æŒ',
            'ä¹°å…¥': 'ä¹°å…¥', 'å¢žæŒ': 'å¢žæŒ', 'æŒæœ‰': 'æŒæœ‰'
        }
        
        text = ' '.join(lines[:20]).lower()
        for eng, chn in rating_keywords.items():
            if eng in text:
                return chn
        return ""
    
    def _extract_target_price(self, lines):
        """Extract target price."""
        import re
        text = ' '.join(lines[:20])
        
        # Look for price patterns
        price_patterns = [
            r'ç›®æ ‡ä»·[ï¼š:]?\s*([Â¥$]?\d+\.?\d*)',
            r'target price[ï¼š:]?\s*([Â¥$]?\d+\.?\d*)',
            r'([Â¥$]?\d+\.?\d*)\s*å…ƒ',
            r'([Â¥$]?\d+\.?\d*)\s*æ¸¯å…ƒ'
        ]
        
        for pattern in price_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1)
        return ""
    
    def _extract_source(self, filename):
        """Extract source institution from filename."""
        sources = {
            'jpmorgan': 'æ‘©æ ¹å¤§é€š', 'jp': 'æ‘©æ ¹å¤§é€š', 'jpm': 'æ‘©æ ¹å¤§é€š',
            'goldman': 'é«˜ç››', 'gs': 'é«˜ç››',
            'morgan': 'æ‘©æ ¹å£«ä¸¹åˆ©', 'ms': 'æ‘©æ ¹å£«ä¸¹åˆ©',
            'citi': 'èŠ±æ——', 'citigroup': 'èŠ±æ——',
            'ubs': 'ç‘žé“¶', 'credit': 'ç‘žä¿¡',
            'bofa': 'ç¾Žé“¶', 'bank of america': 'ç¾Žé“¶'
        }
        
        filename_lower = filename.lower()
        for key, value in sources.items():
            if key in filename_lower:
                return value
        
        return "ç ”ç©¶æœºæž„"
    
    def combine_summaries(self, summaries):
        """Combine multiple summaries into one comprehensive summary."""
        if not summaries:
            return "æœªæ‰¾åˆ°æœ‰æ•ˆåˆ†æžç»“æžœ"
        
        if len(summaries) == 1:
            return summaries[0]
        
        # Extract common elements
        sources = set()
        companies = set()
        ratings = []
        
        for summary in summaries:
            # Extract source
            if 'è§‚ç‚¹:' in summary:
                source = summary.split('è§‚ç‚¹:')[0].strip()
                sources.add(source)
            
            # Extract ratings
            if 'ä¹°å…¥' in summary:
                ratings.append('ä¹°å…¥')
            elif 'å¢žæŒ' in summary:
                ratings.append('å¢žæŒ')
            elif 'æŒæœ‰' in summary:
                ratings.append('æŒæœ‰')
        
        # Create combined summary
        if sources:
            source_text = 'ã€'.join(list(sources)[:2])  # Max 2 sources
        else:
            source_text = "å¤šå®¶æœºæž„"
        
        # Determine consensus rating
        if ratings:
            most_common_rating = max(set(ratings), key=ratings.count)
        else:
            most_common_rating = "å…³æ³¨"
        
        combined = f"{source_text}ç»¼åˆè§‚ç‚¹:\n"
        combined += f"ä¸€è‡´{most_common_rating}è¯„çº§\n"
        combined += f"åŸºäºŽ{len(summaries)}ä»½ç ”æŠ¥çš„ç»¼åˆåˆ†æž\n"
        combined += "è¯¦ç»†è§‚ç‚¹è¯·è§ä¸Šæ–¹å„æœºæž„åˆ†æž"
        
        return combined[:300]
