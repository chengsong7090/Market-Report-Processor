#!/usr/bin/env python3
"""
WeChat Summarizer - Specialized summarizer for WeChat sharing

Creates concise, readable summaries optimized for WeChat group sharing.
Focuses on buy/sell recommendations, key data points, and investment logic.
"""

import re
from src.llm_summarizer import LLMSummarizer

class WeChatSummarizer:
    def __init__(self):
        """Initialize WeChat summarizer with LLM backend."""
        self.llm_summarizer = LLMSummarizer()
        
    def generate_wechat_summary(self, pdf_text, filename=""):
        """
        Generate WeChat-friendly summary from PDF text.
        
        Args:
            pdf_text (str): Raw text extracted from PDF
            filename (str): Original filename for source attribution
            
        Returns:
            str: Formatted WeChat summary (â‰¤300 characters)
        """
        try:
            # Create specialized prompt for WeChat format
            wechat_prompt = self._create_wechat_prompt(pdf_text, filename)
            
            # Get LLM summary using existing infrastructure
            if self.llm_summarizer.deepseek_available:
                try:
                    print("ðŸ“± æ­£åœ¨ä½¿ç”¨DeepSeekç”Ÿæˆå¾®ä¿¡åˆ†äº«æ ¼å¼...")
                    summary = self._summarize_with_deepseek_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ DeepSeekå¤±è´¥: {e}")
            
            if self.llm_summarizer.gemini_available:
                try:
                    print("ðŸ“± æ­£åœ¨ç”Ÿæˆå¾®ä¿¡åˆ†äº«æ ¼å¼...")
                    summary = self._summarize_with_gemini_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ Geminiå¤±è´¥: {e}")
            
            if self.llm_summarizer.qwen_available:
                try:
                    print("ðŸ“± ä½¿ç”¨Qwenç”Ÿæˆå¾®ä¿¡æ ¼å¼...")
                    summary = self._summarize_with_qwen_wechat(wechat_prompt)
                    return self._format_wechat_output(summary, filename)
                except Exception as e:
                    print(f"âš ï¸ Qwenå¤±è´¥: {e}")
            
            # Fallback to basic extraction
            return self._fallback_summary(pdf_text, filename)
            
        except Exception as e:
            return f"âŒ åˆ†æžå¤±è´¥: {filename}\né”™è¯¯: {str(e)}"
    
    def _create_wechat_prompt(self, pdf_text, filename):
        """Create specialized prompt for WeChat summary."""
        # Truncate text if too long
        max_length = 15000
        if len(pdf_text) > max_length:
            pdf_text = pdf_text[:max_length] + "\n\n[å†…å®¹å·²æˆªæ–­...]"
        
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œéœ€è¦ä¸ºå¾®ä¿¡ç¾¤åˆ†äº«åˆ›å»ºå†…å®¹è¯¦å®žã€è®ºæ®å……åˆ†çš„ç ”æŠ¥æ€»ç»“ã€‚

**å¤„ç†æµç¨‹ï¼š**
1.  **è¯†åˆ«æ¥æºä¸Žå¯¹è±¡**ï¼šé¦–å…ˆå‡†ç¡®è¯†åˆ«ç ”æŠ¥çš„**å‘å¸ƒæœºæž„**ï¼ˆå¦‚é«˜ç››ã€æ‘©æ ¹å¤§é€šï¼‰åŠå…¶ä¸»è¦åˆ†æžçš„**å…¬å¸æˆ–è¡Œä¸š**ã€‚
2.  **æç‚¼æ ¸å¿ƒè§‚ç‚¹ä¸Žç»“è®º**ï¼šå®¢è§‚æç‚¼æŠ¥å‘Šçš„æ ¸å¿ƒåˆ¤æ–­ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºŽï¼šè¡Œä¸šè¶‹åŠ¿é¢„æµ‹ã€å…¬å¸å‰æ™¯å±•æœ›ã€æŠ•èµ„è¯„çº§ï¼ˆå¢žæŒ/ä¹°å…¥/ä¸­æ€§ç­‰ï¼‰åŠç›®æ ‡ä»·ã€‚
3.  **è¯¦å®žæ€»ç»“æ”¯æ’‘è®ºæ®**ï¼šè¿™æ˜¯å…³é”®ã€‚å¿…é¡»æ·±å…¥æå–æ”¯æŒå…¶æ ¸å¿ƒç»“è®ºçš„**2-3ä¸ªä¸»è¦é€»è¾‘å’Œå…³é”®æ•°æ®**ä½œä¸ºæ”¯æ’‘è®ºç‚¹ï¼Œè¦æ±‚å…·ä½“ã€è¯¦å®žã€‚
4.  **èšç„¦å…³é”®æ•°æ®**ï¼šçªå‡ºå‘ˆçŽ°æœ€é‡è¦çš„å…·ä½“æ•°æ®ï¼Œå¦‚å¢žé•¿çŽ‡ã€å¸‚åœºä»½é¢ã€è§„æ¨¡é¢„æµ‹ã€ä¼°å€¼å€æ•°ã€è®¢å•æƒ…å†µç­‰ã€‚
5.  **ä¸¥æ ¼è§„é¿å†…å®¹**ï¼šåˆ é™¤æ‰€æœ‰é£Žé™©æç¤ºã€å…è´£å£°æ˜Žã€ä¸»è§‚è‡†æ–­åŠå†—ä½™èƒŒæ™¯ä¿¡æ¯ã€‚

**è¾“å‡ºè¦æ±‚ï¼š**
-   **è¯­è¨€**ï¼šçº¯ä¸­æ–‡ï¼Œè¡Œæ–‡ä¸“ä¸šä¸”å¹³å®žï¼Œé€‚åˆé‡‘èžä»Žä¸šè€…é˜…è¯»ã€‚
-   **å­—æ•°**ï¼š**200è‡³400å­—ä¹‹é—´**ï¼Œç¡®ä¿å†…å®¹å……å®žä¸”ä¸è¶…é™ã€‚
-   **å†…å®¹**ï¼šå¿…é¡»ä¸¥æ ¼åŸºäºŽç ”æŠ¥åŽŸæ–‡ï¼Œå®¢è§‚å‘ˆçŽ°å…¶è§‚ç‚¹ä¸Žè®ºæ®ã€‚

**è¾“å‡ºæ ¼å¼ï¼š**
[æœºæž„åç§°]å‘å¸ƒå…³äºŽ[å…¬å¸åç§°/è¡Œä¸šåç§°]çš„æœ€æ–°ç ”ç©¶ã€‚[å…¶ä¸»è¦è§‚ç‚¹/è®¤ä¸º]ï¼š[ç”¨1-2å¥è¯æ¦‚æ‹¬æ ¸å¿ƒåˆ¤æ–­æˆ–è¶‹åŠ¿é¢„æµ‹]ã€‚
**æ ¸å¿ƒæ”¯æ’‘è®ºæ®åŒ…æ‹¬**ï¼š
1.  [ç¬¬ä¸€ä¸ªè¯¦ç»†æ”¯æ’‘è®ºç‚¹ï¼ŒåŒ…å«å…·ä½“æ•°æ®æˆ–äº‹å®ž]ï¼›
2.  [ç¬¬äºŒä¸ªè¯¦ç»†æ”¯æ’‘è®ºç‚¹ï¼ŒåŒ…å«å…·ä½“æ•°æ®æˆ–äº‹å®ž]ï¼›
3.  [ï¼ˆå¯é€‰ï¼‰ç¬¬ä¸‰ä¸ªè¯¦ç»†æ”¯æ’‘è®ºç‚¹ï¼ŒåŒ…å«å…·ä½“æ•°æ®æˆ–äº‹å®ž]ã€‚
(åŸºäºŽä¸Šè¿°åˆ†æžï¼Œ[æœºæž„åç§°]ç»´æŒ/ç»™äºˆ[è‚¡ç¥¨ä»£ç ]"[è¯„çº§]"è¯„çº§åŠç›®æ ‡ä»·[ç›®æ ‡ä»·]ã€‚)

**å‚è€ƒæ¡ˆä¾‹ï¼š**
é«˜ç››å‘å¸ƒå…³äºŽä¸­å›½åŠå¯¼ä½“è¡Œä¸šçš„æœ€æ–°ç ”ç©¶ã€‚å…¶è®¤ä¸ºä¸­å›½åŠå¯¼ä½“è¡Œä¸šæ­£è¿Žæ¥æ–°ä¸€è½®èµ„æœ¬æ”¯å‡ºæ‰©å¼ ä¸ŽæŠ€æœ¯å‡çº§ã€‚
**æ ¸å¿ƒæ”¯æ’‘è®ºæ®åŒ…æ‹¬**ï¼š
1.  èµ„æœ¬æ”¯å‡ºå¤§å¹…ä¸Šè°ƒï¼šå°†2025-2030å¹´è¡Œä¸šèµ„æœ¬æ”¯å‡ºé¢„æµ‹ä¸Šè°ƒè‡³430-460äº¿ç¾Žå…ƒï¼ŒæŠ•èµ„é‡ç‚¹æ›´å¤šè½¬å‘å­˜å‚¨å™¨å’Œå…ˆè¿›åˆ¶ç¨‹èŠ‚ç‚¹ï¼›
2.  æœ¬åœŸåŽ‚å•†æ·±åº¦å—ç›Šï¼šé¢„è®¡æœ¬åœŸåŠå¯¼ä½“ç”Ÿäº§è®¾å¤‡ï¼ˆSPEï¼‰ä¾›åº”å•†çš„å¸‚åœºä»½é¢å°†ä»Ž2025å¹´çš„26%æ˜¾è‘—æå‡è‡³2030å¹´çš„36%ï¼›
3.  å…‰åˆ»æœºéœ€æ±‚åºžå¤§ï¼šæå‡ºåˆ°2035å¹´ï¼Œä¸­å›½éœ€æ–°å¢žè¶…è¿‡2261å°å…‰åˆ»æœºæ‰èƒ½æ»¡è¶³å…¨éƒ¨èŠ¯ç‰‡éœ€æ±‚ï¼Œæ­ç¤ºäº†å·¨å¤§çš„è®¾å¤‡å¸‚åœºç©ºé—´ã€‚
é«˜ç››çœ‹å¥½ä¸­å›½åŠå¯¼ä½“å‘å±•çš„æ ¸å¿ƒé€»è¾‘è¿˜åŒ…æ‹¬åºžå¤§çš„æœ¬åœŸå¸‚åœºã€æŠ€æœ¯ç”Ÿæ€æŒç»­æˆç†ŸåŠç”Ÿæˆå¼AIæŽ¨åŠ¨ä¾›åº”é“¾å‘å±•ï¼Œå¹¶å…·ä½“çœ‹å¥½åŠå¯¼ä½“è®¾å¤‡ï¼ˆSPEï¼‰åŠå…ˆè¿›åˆ¶ç¨‹ç›¸å…³å­è¡Œä¸šï¼ˆIPã€è®¾è®¡ã€ä»£å·¥ã€å°è£…ç­‰ï¼‰ã€‚

è¯·æ ¹æ®ä¸Šè¿°è§„åˆ™ï¼Œå¯¹ä»¥ä¸‹æ–‡æ¡£è¿›è¡Œåˆ†æžå’Œæ€»ç»“ï¼š
æ–‡æ¡£: {filename}
å†…å®¹: {pdf_text}
"""
        return prompt
    
    def _summarize_with_deepseek_wechat(self, prompt):
        """Use DeepSeek for WeChat summary."""
        response = self.llm_summarizer.deepseek_client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œæ“…é•¿åˆ›å»ºç®€æ´çš„å¾®ä¿¡åˆ†äº«å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        return response.choices[0].message.content.strip()
    
    def _summarize_with_gemini_wechat(self, prompt):
        """Use Gemini for WeChat summary."""
        response = self.llm_summarizer.model.generate_content(prompt)
        return response.text.strip()
    
    def _summarize_with_qwen_wechat(self, prompt):
        """Use Qwen for WeChat summary."""
        response = self.llm_summarizer.qwen_client.chat.completions.create(
            model="qwen-plus",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„é‡‘èžåˆ†æžå¸ˆï¼Œæ“…é•¿åˆ›å»ºç®€æ´çš„å¾®ä¿¡åˆ†äº«å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            max_tokens=500
        )
        return response.choices[0].message.content.strip()
    
    def _format_wechat_output(self, summary, filename):
        """Format and validate WeChat output."""
        # Clean up the summary
        summary = summary.strip()
        
        # Remove any markdown formatting
        summary = re.sub(r'\*\*([^*]+)\*\*', r'\1', summary)
        summary = re.sub(r'\*([^*]+)\*', r'\1', summary)
        
        # Ensure it's not too long (400 characters max)
        if len(summary) > 400:
            # Try to truncate at sentence boundary
            sentences = summary.split('ã€‚')
            truncated = ""
            for sentence in sentences:
                if len(truncated + sentence + "ã€‚") <= 395:
                    truncated += sentence + "ã€‚"
                else:
                    break
            if truncated:
                summary = truncated
            else:
                summary = summary[:395] + "..."
        
        return summary
    
    def _fallback_summary(self, pdf_text, filename):
        """Create basic summary when LLMs are unavailable."""
        # Extract key information using simple text processing
        lines = pdf_text.split('\n')
        
        # Look for common patterns
        company_name = self._extract_company_name(lines)
        rating = self._extract_rating(lines)
        target_price = self._extract_target_price(lines)
        source = self._extract_source(filename)
        
        summary = f"{source}è§‚ç‚¹: {company_name}\n"
        if rating:
            summary += f"{rating}è¯„çº§"
        if target_price:
            summary += f"ï¼Œç›®æ ‡ä»·{target_price}"
        
        summary += f"\nðŸ“„ æ¥æº: {filename}"
        
        return summary[:400]
    
    def _extract_company_name(self, lines):
        """Extract company name from text."""
        for line in lines[:10]:  # Check first 10 lines
            if any(keyword in line for keyword in ['è‚¡ä»½', 'å…¬å¸', 'ç§‘æŠ€', 'é›†å›¢']):
                # Simple extraction - could be improved
                words = line.split()
                for word in words:
                    if any(keyword in word for keyword in ['è‚¡ä»½', 'å…¬å¸', 'ç§‘æŠ€', 'é›†å›¢']):
                        return word[:10]  # Limit length
        return "ç›®æ ‡å…¬å¸"
    
    def _extract_rating(self, lines):
        """Extract investment rating."""
        rating_keywords = {
            'buy': 'ä¹°å…¥', 'overweight': 'å¢žæŒ', 'hold': 'æŒæœ‰', 
            'sell': 'å–å‡º', 'underweight': 'å‡æŒ',
            'ä¹°å…¥': 'ä¹°å…¥', 'å¢žæŒ': 'å¢žæŒ', 'æŒæœ‰': 'æŒæœ‰'
        }
        
        text = ' '.join(lines[:20]).lower()
        for eng, chn in rating_keywords.items():
            if eng in text:
                return chn
        return ""
    
    def _extract_target_price(self, lines):
        """Extract target price."""
        import re
        text = ' '.join(lines[:20])
        
        # Look for price patterns
        price_patterns = [
            r'ç›®æ ‡ä»·[ï¼š:]?\s*([Â¥$]?\d+\.?\d*)',
            r'target price[ï¼š:]?\s*([Â¥$]?\d+\.?\d*)',
            r'([Â¥$]?\d+\.?\d*)\s*å…ƒ',
            r'([Â¥$]?\d+\.?\d*)\s*æ¸¯å…ƒ'
        ]
        
        for pattern in price_patterns:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                return match.group(1)
        return ""
    
    def _extract_source(self, filename):
        """Extract source institution from filename."""
        sources = {
            'jpmorgan': 'æ‘©æ ¹å¤§é€š', 'jp': 'æ‘©æ ¹å¤§é€š', 'jpm': 'æ‘©æ ¹å¤§é€š',
            'goldman': 'é«˜ç››', 'gs': 'é«˜ç››',
            'morgan': 'æ‘©æ ¹å£«ä¸¹åˆ©', 'ms': 'æ‘©æ ¹å£«ä¸¹åˆ©',
            'citi': 'èŠ±æ——', 'citigroup': 'èŠ±æ——',
            'ubs': 'ç‘žé“¶', 'credit': 'ç‘žä¿¡',
            'bofa': 'ç¾Žé“¶', 'bank of america': 'ç¾Žé“¶'
        }
        
        filename_lower = filename.lower()
        for key, value in sources.items():
            if key in filename_lower:
                return value
        
        return "ç ”ç©¶æœºæž„"
    
    def combine_summaries(self, summaries):
        """Combine multiple summaries into one comprehensive summary."""
        if not summaries:
            return "æœªæ‰¾åˆ°æœ‰æ•ˆåˆ†æžç»“æžœ"
        
        if len(summaries) == 1:
            return summaries[0]
        
        # Extract common elements
        sources = set()
        companies = set()
        ratings = []
        
        for summary in summaries:
            # Extract source
            if 'è§‚ç‚¹:' in summary:
                source = summary.split('è§‚ç‚¹:')[0].strip()
                sources.add(source)
            
            # Extract ratings
            if 'ä¹°å…¥' in summary:
                ratings.append('ä¹°å…¥')
            elif 'å¢žæŒ' in summary:
                ratings.append('å¢žæŒ')
            elif 'æŒæœ‰' in summary:
                ratings.append('æŒæœ‰')
        
        # Create combined summary
        if sources:
            source_text = 'ã€'.join(list(sources)[:2])  # Max 2 sources
        else:
            source_text = "å¤šå®¶æœºæž„"
        
        # Determine consensus rating
        if ratings:
            most_common_rating = max(set(ratings), key=ratings.count)
        else:
            most_common_rating = "å…³æ³¨"
        
        combined = f"{source_text}ç»¼åˆè§‚ç‚¹:\n"
        combined += f"ä¸€è‡´{most_common_rating}è¯„çº§\n"
        combined += f"åŸºäºŽ{len(summaries)}ä»½ç ”æŠ¥çš„ç»¼åˆåˆ†æž\n"
        combined += "è¯¦ç»†è§‚ç‚¹è¯·è§ä¸Šæ–¹å„æœºæž„åˆ†æž"
        
        return combined[:400]
